---
title: Providers
weight: 20
description:
---

Learn how to configure agentgateway for a particular LLM.

## Native providers

{{< cards >}}
  {{< card link="openai" title="OpenAI" >}}
  {{< card link="anthropic" title="Anthropic" >}}
  {{< card link="gemini" title="Google Gemini" >}}
  {{< card link="vertex" title="Google Vertex AI" >}}
  {{< card link="bedrock" title="Amazon Bedrock" >}}
  {{< card link="azureopenai" title="Azure OpenAI" >}}
{{< /cards >}}

## OpenAI-compatible providers

{{< cards >}}
  {{< card link="openai-compatible" title="OpenAI-compatible providers" >}}
{{< /cards >}}

Popular OpenAI-compatible providers include Mistral, DeepSeek, Groq, Together AI, Perplexity, and Fireworks AI.

## Self-hosted solutions

{{< cards >}}
  {{< card link="ollama" title="Ollama" >}}
  {{< card link="vllm" title="vLLM" >}}
{{< /cards >}}

## Advanced configurations

{{< cards >}}
  {{< card link="multiple-endpoints" title="Multiple endpoints" >}}
  {{< card link="httpbun" title="Mock LLM with httpbun" >}}
{{< /cards >}}

